{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://automaticaddison.com/develop-a-neural-network-to-classify-handwritten-digits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1534/3750 [===========>..................] - ETA: 2:30 - loss: 0.4988 - accuracy: 0.8418"
     ]
    }
   ],
   "source": [
    "# Project: Detect Handwritten Digits Using the MNIST Data Set\n",
    "# Author: Addison Sears-Collins\n",
    "# Date created: January 4, 2021\n",
    " \n",
    "import tensorflow as tf # Machine learning library\n",
    "from tensorflow import keras # Library for neural networks\n",
    "from tensorflow.keras.datasets import mnist # MNIST data set\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "num_classes = 10 # Number of distinct labels\n",
    " \n",
    "def generate_neural_network(x_train):\n",
    "  \"\"\"\n",
    "  Create a convolutional neural network.\n",
    "  :x_train: Training images of handwritten digits (grayscale)\n",
    "  :return: Neural network\n",
    "  \"\"\"\n",
    "  model = keras.Sequential()\n",
    " \n",
    "  # Add a convolutional layer to the neural network\n",
    "  model.add(Conv2D(filters=6, kernel_size=(\n",
    "        5, 5), activation='relu', padding='same', input_shape=x_train.shape[\n",
    "        1:]))\n",
    "  model.add(MaxPooling2D()) # subsampling using max pooling\n",
    " \n",
    "  # Add a convolutional layer to the neural network \n",
    "  model.add(Conv2D(filters=16, kernel_size=(5, 5), activation='relu'))\n",
    "  model.add(MaxPooling2D())\n",
    " \n",
    "  # Add the dense layers\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(units=120, activation='relu'))\n",
    "  model.add(Dense(units=84, activation='relu'))\n",
    " \n",
    "  # Softmax transforms the prediction into a probability\n",
    "  # The highest probability corresponds to the category of the image (i.e. 0-9)\n",
    "  model.add(Dense(units=num_classes, activation='softmax'))\n",
    " \n",
    "  return model\n",
    " \n",
    "def tf_and_gpu_ok():\n",
    "  \"\"\"\n",
    "  Test if TensorFlow and GPU support are working properly.\n",
    "  \"\"\"\n",
    "  # Test code to see if Tensorflow is installed properly\n",
    "  print(\"Tensorflow:\", tf.__version__)\n",
    "  print(\"Tensorflow Git:\", tf.version.GIT_VERSION)  \n",
    " \n",
    "  # See if you can use the GPU on your computer\n",
    "  print(\"CUDA ON\" if tf.test.is_built_with_cuda() else \"CUDA OFF\")\n",
    "  print(\"GPU ON\" if tf.test.is_gpu_available() else \"GPU OFF\")\n",
    " \n",
    "def main():\n",
    " \n",
    "  # Uncomment to check if everything is working properly\n",
    "  #tf_and_gpu_ok()\n",
    " \n",
    "  # Load the MNIST data set and make sure the training and testing\n",
    "  # data are four dimensions (which is what Keras needs)\n",
    "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "  x_train = np.reshape(x_train, np.append(x_train.shape, (1)))\n",
    "  x_test = np.reshape(x_test, np.append(x_test.shape, (1)))\n",
    " \n",
    "  # Uncomment to display the dimensions of the training data set and the \n",
    "  # testing data set\n",
    "  #print('x_train', x_train.shape, ' --- x_test', x_test.shape)\n",
    "  #print('y_train', y_train.shape, ' --- y_test', y_test.shape)  \n",
    " \n",
    "  # Normalize image intensity values to a range between 0 and 1 (from 0-255)\n",
    "  x_train = x_train.astype('float32')\n",
    "  x_test = x_test.astype('float32')\n",
    "  x_train = x_train / 255\n",
    "  x_test = x_test / 255\n",
    " \n",
    "  # Uncomment to display the first 3 labels \n",
    "  #print('First 3 labels for train set:', y_train[0], y_train[1], y_train[2])\n",
    "  #print('First 3 labels for testing set:', y_test[0], y_test[1], y_test[2])\n",
    "   \n",
    "  # Perform one-hot encoding\n",
    "  y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "  y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    " \n",
    "  # Create the neural network\n",
    "  model = generate_neural_network(x_train)\n",
    "     \n",
    "  # Uncomment to print the summary statistics of the neural network\n",
    "  #print(model.summary())  \n",
    " \n",
    "  # Configure the neural network\n",
    "  model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "     \n",
    "  start = time()\n",
    "  history = model.fit(x_train, y_train, batch_size=16, epochs=5, validation_data=(x_test, y_test), shuffle=True)\n",
    "  training_time = time() - start\n",
    "  print(f'Training time: {training_time}')\n",
    "     \n",
    "  # A measure of how well the neural network learned the training data\n",
    "  # The lower, the better\n",
    "  print(\"Minimum Loss: \", min(history.history['loss']))\n",
    " \n",
    "  # A measure of how well the neural network did on the validation data set\n",
    "  # The lower, the better\n",
    "  print(\"Minimum Validation Loss: \", min(history.history['val_loss']))\n",
    " \n",
    "  # Maximum percentage of correct predictions on the training data\n",
    "  # The higher, the better\n",
    "  print(\"Maximum Accuracy: \", max(history.history['accuracy']))\n",
    " \n",
    "  # Maximum percentage of correct predictions on the validation data\n",
    "  # The higher, the better\n",
    "  print(\"Maximum Validation Accuracy: \", max(history.history['val_accuracy']))\n",
    "     \n",
    "  # Plot the key statistics\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title(\"Mean Squared Error for the Neural Network on the MNIST Data\")  \n",
    "  plt.ylabel(\"Mean Squared Error\")\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.legend(['Training Loss', 'Validation Loss', 'Training Accuracy', \n",
    "    'Validation Accuracy'], loc='center right') \n",
    "  plt.show() # Press Q to close the graph\n",
    "     \n",
    "  # Save the neural network in Hierarchical Data Format version 5 (HDF5) format\n",
    "  model.save('mnist_nnet.h5')\n",
    "    \n",
    "  # Import the saved model\n",
    "  model = keras.models.load_model('mnist_nnet.h5')\n",
    "  print(\"\\n\\nNeural network has loaded successfully...\\n\")\n",
    "         \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
